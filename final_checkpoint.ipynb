{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f6f669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import logging\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "975c344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def unzip_files(zip_file_path):\n",
    "#     with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "#         zip_ref.extractall()\n",
    "\n",
    "\n",
    "# zip_file_path = 'archive.zip'\n",
    "\n",
    "\n",
    "# unzip_files(zip_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b70022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(image_file, train_labels):\n",
    "    label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
    "    label_path = os.path.join(train_labels, label_file)\n",
    "    \n",
    "    with open(label_path, \"r\") as f:\n",
    "        labels = f.read().strip().split(\"\\n\")\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def plot_object_detections(ax, image, labels):\n",
    "    for label in labels:\n",
    "        if len(label.split()) != 5:\n",
    "            continue\n",
    "        class_id, x_center, y_center, width, height = map(float, label.split())\n",
    "        x_min = int((x_center - width/2) * image.shape[1])\n",
    "        y_min = int((y_center - height/2) * image.shape[0])\n",
    "        x_max = int((x_center + width/2) * image.shape[1])\n",
    "        y_max = int((y_center + height/2) * image.shape[0])\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 3)\n",
    "\n",
    "    ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    ax.axis('off')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d150f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.2  Python-3.9.13 torch-2.0.0 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\Sway\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 19.1MB/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Sway\\ece50024\\datasets\\valid\\labels... 300 images, 0 backgrounds, 0 corrupt: 100%|██████████| 300/300 [00:00<00:00, 872.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Sway\\ece50024\\datasets\\valid\\images\\Pias--359-_PNG.rf.43bcf36efe5cf8c37552d2c45fffea60.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Sway\\ece50024\\datasets\\valid\\images\\Pias--360-_PNG.rf.8405b0e44009a9300e0a1100ccf7d5b3.jpg: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Sway\\ece50024\\datasets\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 19/19 [00:09<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300       2568    0.00709     0.0629    0.00419    0.00327\n",
      "            motorcycle        300         32    0.00516      0.906    0.00683    0.00293\n",
      "              airplane        300        425     0.0833    0.00235     0.0463     0.0417\n",
      "                   bus        300        842     0.0145     0.0451    0.00757    0.00486\n",
      "                  boat        300          2          0          0          0          0\n",
      "         traffic light        300        110          0          0          0          0\n",
      "          fire hydrant        300        335          0          0          0          0\n",
      "             stop sign        300        142          0          0          0          0\n",
      "         parking meter        300          1          0          0          0          0\n",
      "                 bench        300        192     0.0105     0.0521    0.00633    0.00276\n",
      "                  bird        300          1          0          0          0          0\n",
      "                   cat        300         60          0          0          0          0\n",
      "                   dog        300         19          0          0          0          0\n",
      "                 horse        300        252          0          0          0          0\n",
      "                 sheep        300         84          0          0          0          0\n",
      "                   cow        300         62          0          0          0          0\n",
      "              elephant        300          9          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 22.5ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# random_images = random.sample(image_files, 16)\n",
    "model = YOLO(\"yolov8x.pt\") \n",
    "\n",
    "\n",
    "\n",
    "results = model.val(data='data_1.yaml')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fcc04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Functions for image -> image np array\n",
    "\n",
    "def image_to_normalized_array(image):\n",
    "    \"\"\"\n",
    "    Converts a PIL Image object to a normalized (0.0 to 1.0) float32 image array.\n",
    "\n",
    "    Parameters:\n",
    "        image (PIL.Image): The input PIL Image object.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The normalized image array with pixel values between 0.0 and 1.0.\n",
    "    \"\"\"\n",
    "    # Convert the PIL Image to a NumPy array\n",
    "    img_array = np.asarray(image)\n",
    "\n",
    "    # Convert the array's data type to float32 for normalization\n",
    "    img_array = img_array.astype(np.float32)\n",
    "\n",
    "    # Normalize pixel values to be between 0.0 and 1.0\n",
    "    img_array /= 255.0\n",
    "\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "101482a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1925093448.py, line 65)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Sway\\AppData\\Local\\Temp\\ipykernel_24432\\1925093448.py\"\u001b[1;36m, line \u001b[1;32m65\u001b[0m\n\u001b[1;33m    Example usage:\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Best version\n",
    "\n",
    "# Plug-and-Play ADMM denoising\n",
    "\n",
    "\n",
    "def update_x(x_prev, v_prev, u_prev, rho, f):\n",
    "    x = (f + rho * (v_prev - u_prev)) / (1 + rho)\n",
    "    return x\n",
    "\n",
    "def denoiser(image, sigma):\n",
    "    return denoise_tv_chambolle(image, weight=sigma)\n",
    "\n",
    "def update_v(x, u_prev, lambda_val, rho):\n",
    "    sigma = np.sqrt(lambda_val / rho)\n",
    "    return denoiser(x + u_prev, sigma)\n",
    "\n",
    "def update_u(u_prev, x, v):\n",
    "    return u_prev + (x - v)\n",
    "\n",
    "def calc_delta(x, x_prev, v, v_prev, u, u_prev):\n",
    "    delta = np.sqrt(np.mean((x - x_prev)**2) + np.mean((v - v_prev)**2) + np.mean((u - u_prev)**2))\n",
    "    return delta\n",
    "\n",
    "def plug_and_play_admm(f, lambda_val, rho_0, eta, gamma, tol, max_iterations):\n",
    "    x = f.copy()\n",
    "    v = f.copy()\n",
    "    u = np.zeros_like(f)\n",
    "\n",
    "    rho = rho_0\n",
    "    delta = np.inf\n",
    "    k = 0\n",
    "\n",
    "    while delta >= tol and k < max_iterations:\n",
    "        x_prev = x.copy()\n",
    "        v_prev = v.copy()\n",
    "        u_prev = u.copy()\n",
    "\n",
    "        x = update_x(x_prev, v_prev, u_prev, rho, f)\n",
    "        v = update_v(x, u_prev, lambda_val, rho)\n",
    "        u = update_u(u_prev, x, v)\n",
    "\n",
    "        delta_prev = delta\n",
    "        delta = calc_delta(x, x_prev, v, v_prev, u, u_prev)\n",
    "\n",
    "        if delta >= eta * delta_prev:\n",
    "            rho *= gamma\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    return x\n",
    "\n",
    "def noise_gray(image, noise_level):\n",
    "  noise = np.random.normal(scale=noise_level, size=image.shape)\n",
    "  noisy_image = image + noise\n",
    "  noisy_image = np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
    "  return noisy_image\n",
    "\n",
    "# image = cv2.imread(dir_path + 'dog_on_grass.jpg')\n",
    "# image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# image_array = image_to_normalized_array(image_gray)\n",
    "\n",
    "# noisy_image = noise_gray(image_gray, 30)\n",
    "# noisy_array = image_to_normalized_array(noisy_image)\n",
    "\n",
    "# Example usage:\n",
    "# f: Blurred image\n",
    "# lambda_val: Regularization parameter\n",
    "# rho_0: Initial value of rho\n",
    "# eta: Convergence criteria parameter\n",
    "# gamma: Parameter for adjusting rho\n",
    "# tol: Convergence tolerance\n",
    "# max_iterations: Maximum number of iterations\n",
    "# deblurred_image = plug_and_play_admm(f, lambda_val, rho_0, eta, gamma, tol, max_iterations)\n",
    "# denoised_array = plug_and_play_admm(noisy_array, lambda_val=0.001, rho_0=0.00001, eta=0.5, gamma=1.4, tol=0.001, max_iterations=100)\n",
    "\n",
    "\n",
    "# # Calculate PSNR and SSIM for noisy image\n",
    "# psnr_noisy, ssim_noisy = compare_images(img_array, noisy_array)\n",
    "# psnr_denoised, ssim_denoised = compare_images(img_array, denoised_array)\n",
    "# print(f\"Noisy Image PSNR: {psnr_noisy:.2f}, SSIM: {ssim_noisy:.4f}\")\n",
    "# print(f\"Denoised Image PSNR: {psnr_denoised:.2f}, SSIM: {ssim_denoised:.4f}\")\n",
    "\n",
    "# # Display the deblurred image\n",
    "# plt.figure(figsize=(16, 8))\n",
    "\n",
    "# plt.subplot(1, 3, 1)\n",
    "# plt.imshow(image_array, cmap='gray')\n",
    "# plt.title('Original Image')\n",
    "\n",
    "# plt.subplot(1, 3, 2)\n",
    "# plt.imshow(noisy_array, cmap='gray')\n",
    "# plt.title('Blurred Image')\n",
    "\n",
    "# plt.subplot(1, 3, 3)\n",
    "# plt.imshow(denoised_array, cmap='gray')\n",
    "# plt.title('Deblurred Image')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70dfd4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_and_save(dir_path):\n",
    "    for filename in os.listdir(dir_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(dir_path, filename)\n",
    "            image = cv2.imread(img_path)\n",
    "            image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            noisy_image = noise_gray(image_gray, 30)\n",
    "            noisy_img_path = os.path.join(\"gray_noise_images\", '' + filename)\n",
    "            cv2.imwrite(noisy_img_path, noisy_image)\n",
    "add_noise_and_save('original/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8abdc02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.2  Python-3.9.13 torch-2.0.0 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Sway\\ece50024\\datasets\\valid\\labels... 300 images, 0 backgrounds, 0 corrupt: 100%|██████████| 300/300 [00:00<00:00, 956.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Sway\\ece50024\\datasets\\valid\\images\\Pias--359-_PNG.rf.43bcf36efe5cf8c37552d2c45fffea60.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Sway\\ece50024\\datasets\\valid\\images\\Pias--360-_PNG.rf.8405b0e44009a9300e0a1100ccf7d5b3.jpg: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Sway\\ece50024\\datasets\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 19/19 [00:09<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300       2568    0.00937     0.0354    0.00586    0.00283\n",
      "            motorcycle        300         32     0.0048      0.375    0.00498    0.00215\n",
      "              airplane        300        425     0.0392    0.00941     0.0202     0.0141\n",
      "                   bus        300        842     0.0125     0.0428     0.0066    0.00379\n",
      "                  boat        300          2          0          0          0          0\n",
      "         traffic light        300        110          0          0          0          0\n",
      "          fire hydrant        300        335     0.0706     0.0896     0.0427     0.0168\n",
      "             stop sign        300        142          0          0          0          0\n",
      "         parking meter        300          1          0          0          0          0\n",
      "                 bench        300        192      0.014     0.0417     0.0145    0.00606\n",
      "                  bird        300          1          0          0          0          0\n",
      "                   cat        300         60          0          0          0          0\n",
      "                   dog        300         19          0          0          0          0\n",
      "                 horse        300        252    0.00889    0.00794    0.00475     0.0024\n",
      "                 sheep        300         84          0          0          0          0\n",
      "                   cow        300         62          0          0          0          0\n",
      "              elephant        300          9          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 22.5ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.val(data='data_1.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16ce760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def denoise_and_save(input_dir_path, output_dir_path):\n",
    "    for filename in os.listdir(input_dir_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            \n",
    "            img_path = os.path.join(input_dir_path, filename)\n",
    "            image = cv2.imread(img_path)\n",
    "            \n",
    "            image_array = image_to_normalized_array(image)\n",
    "\n",
    "            \n",
    "            denoised_array = plug_and_play_admm(image_array, lambda_val=0.001, rho_0=0.00001, eta=0.5, gamma=1.4, tol=0.001, max_iterations=100)\n",
    "\n",
    "           \n",
    "            denoised_image = (denoised_array * 255).astype(np.uint8)\n",
    "\n",
    "          \n",
    "            denoised_img_path = os.path.join(output_dir_path, '' + filename)\n",
    "            cv2.imwrite(denoised_img_path, denoised_image)\n",
    "\n",
    "\n",
    "# denoise_and_save('gray_noise_images', 'gray_denoise_images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "930a244c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.2  Python-3.9.13 torch-2.0.0 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Sway\\ece50024\\datasets\\valid\\labels... 300 images, 0 backgrounds, 0 corrupt: 100%|██████████| 300/300 [00:00<00:00, 519.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Sway\\ece50024\\datasets\\valid\\images\\Pias--359-_PNG.rf.43bcf36efe5cf8c37552d2c45fffea60.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Sway\\ece50024\\datasets\\valid\\images\\Pias--360-_PNG.rf.8405b0e44009a9300e0a1100ccf7d5b3.jpg: 7 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Sway\\ece50024\\datasets\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 19/19 [00:14<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        300       2568    0.00706     0.0424    0.00448     0.0021\n",
      "            motorcycle        300         32    0.00435      0.469    0.00458    0.00208\n",
      "              airplane        300        425          0          0          0          0\n",
      "                   bus        300        842     0.0274     0.0641     0.0147    0.00857\n",
      "                  boat        300          2          0          0          0          0\n",
      "         traffic light        300        110          0          0          0          0\n",
      "          fire hydrant        300        335     0.0525     0.0627     0.0335     0.0145\n",
      "             stop sign        300        142          0          0          0          0\n",
      "         parking meter        300          1          0          0          0          0\n",
      "                 bench        300        192     0.0116     0.0312    0.00981    0.00307\n",
      "                  bird        300          1          0          0          0          0\n",
      "                   cat        300         60          0          0          0          0\n",
      "                   dog        300         19          0          0          0          0\n",
      "                 horse        300        252    0.00936     0.0198    0.00488    0.00292\n",
      "                 sheep        300         84          0          0          0          0\n",
      "                   cow        300         62    0.00775     0.0323    0.00419     0.0025\n",
      "              elephant        300          9          0          0          0          0\n",
      "Speed: 0.3ms preprocess, 35.4ms inference, 0.0ms loss, 7.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8x.pt\") \n",
    "results = model.val(data='data_1.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe992085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
